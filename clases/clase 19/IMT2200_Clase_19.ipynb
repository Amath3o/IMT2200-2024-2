{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 20px; width: 200px\" src=\"https://raw.githubusercontent.com/raxlab/imt2200-data/main/media/logo.jpg\">  IMT 2200 - Introducción a Ciencia de Datos\n",
    "**Pontificia Universidad Católica de Chile**<br>\n",
    "**Instituto de Ingeniería Matemática y Computacional**<br>\n",
    "**Profesor:** Rodrigo A. Carrasco <br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>Clase 19: Aprendizaje Supervisado: Regresiones</center></h1>\n",
    "\n",
    "En este notebook aplicaremos las herramientas implementadas en las librerías de Python `statsmodels` y `scipy` para realizar regresiones.\n",
    "\n",
    "Para implementar regresiones lineales y predecir los outcomes para distintas variables de entrada, podemos usar distintas librerías de `python`:\n",
    "\n",
    "* [scipy.stats](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html).\n",
    "* [statsmodels](http://www.statsmodels.org/stable/regression.html) y \n",
    "* [scikit-learn (sklearn)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "\n",
    "Para efectos de regresiones lineales simples,`scipy`, `statsmodels` y `sklearn` hacen lo mismo. Más en general,  `statsmodels` tiende a ser más fácil para problemas de inferencia (econtrar los parámetros de la regresión y analizar sus incertezas) mientras que  `sklearn` tiene un enfoque de machine learning y es más práctico para realizar predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de Estudio: rendimiento de algunos autos\n",
    "\n",
    "\n",
    "### Descripción del Dataset\n",
    "\n",
    "Para este ejercicio, tenemos como ejemplo un dataset con datos de automóviles, extraidos del repositorio UCI Machine Learning Repository:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/auto+mpg\n",
    "\n",
    "\n",
    "*The data concerns city-cycle fuel consumption in miles per gallon, to be predicted in terms of 3 multivalued discrete and 5 continuous attributes.\" (Quinlan, 1993)* <br>\n",
    "\n",
    "Los datos incluyen datos sobre características del diseño e ingeniería de distintos modelos de autos, como se describe a continuación:\n",
    "\n",
    "- `mpg`: rendimiento de combustible en millas/galón. \n",
    "- `cylinders`: número de cilindros. is Number of cylinders, \n",
    "- `displacement`: desplazamiento (cu.in.), \n",
    "- `horsepower`: potencia en \"caballos de fuerza\". \n",
    "- `weight`: peso (en miles de libras).\n",
    "- `acceleration`: tiempo en recorrer 1/4 de milla desde el reposo.\n",
    "- `origin`: origen \n",
    "- `car name`: nombre del modelo \n",
    "\n",
    "### Objetivo\n",
    "\n",
    "El objetivo es predecir el consumo de un vehículo, en función de sus parámetros de diseño e ingeniería."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datos a analizar\n",
    "\n",
    "El archivo `auto-mpg.csv` será la base que usaremos para este trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import seaborn as sns\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "### 2.1 Exploración inicial\n",
    "\n",
    "Exploremos primero un poco los datos para entender qué relaciones podrían existir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfautos = pd.read_csv(\"data//auto-mpg.csv\")\n",
    "dfautos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfautos.dropna(axis=0, inplace=True)\n",
    "dfautos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfautos['horsepower'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfautos = dfautos[dfautos['horsepower']!='?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfautos['origin'] = dfautos['origin'].astype('category')\n",
    "dfautos['car name'] = dfautos['car name'].astype('category')\n",
    "dfautos['cylinders'] = dfautos['cylinders'].astype('category')\n",
    "dfautos['horsepower'] = dfautos['horsepower'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explorar datos\n",
    "sns.pairplot(dfautos, y_vars='mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dfautos.corr(numeric_only=True), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Rendimiento según diferentes dimensiones\n",
    "\n",
    "Exploremos cuál es el rendimiento promedio para distintas combinaciones de cilindros y hp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=dfautos, y_vars='mpg', x_vars='horsepower', hue='cylinders', height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=dfautos, y='mpg', x='horsepower', hue='cylinders', height=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regresión Lineal\n",
    "\n",
    "### 3.1 Armando el modelo\n",
    "\n",
    "- Nota sobre constantes:\n",
    "\n",
    "Supongamos un caso sencillo, en que tenemos 2 observaciones con un predictor y una variable de respuesta cada una. Tendríamos por lo tanto el siguiente sistema de ecuaciones para el modelo de regresión lineal simple:\n",
    " $$y_1=\\beta_0 + \\beta_1\\cdot x_1$$ $$y_2=\\beta_0 + \\beta_1\\cdot x_2$$ <BR>\n",
    "    \n",
    "En notación matricial, esto sería: \n",
    "    \n",
    "$$\n",
    "\\left [\n",
    "\\begin{array}{c}\n",
    "y_1 \\\\ y_2 \\\\\n",
    "\\end{array}\n",
    "\\right] =\n",
    "\\left [\n",
    "\\begin{array}{cc}\n",
    "1& x_1 \\\\ 1 & x_2 \\\\\n",
    "\\end{array}\n",
    "\\right] \n",
    "\\cdot\n",
    "\\left [\n",
    "\\begin{array}{c}\n",
    "\\beta_0 \\\\ \\beta_1 \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "<BR><BR>\n",
    "    \n",
    "`sklearn` agrega automáticamente la constante `1`, mientras que en  `statsmodels` hay que agregarla explícitamente usando `sm.add_constant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "x = np.array(dfautos.horsepower)\n",
    "y = np.array(dfautos.mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(x)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo OLS (ordinary least squares) entrenado con los datos\n",
    "regr_sm = sm.OLS(y, X)\n",
    "\n",
    "# aplicar fit para entrenar y guardar el modelo\n",
    "results_sm = regr_sm.fit()\n",
    "\n",
    "# entregar informacion general del modelo\n",
    "results_sm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpeficientes beta\n",
    "beta0 = results_sm.params[0]\n",
    "beta1 = results_sm.params[1]\n",
    "beta0, beta1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualizando datos y predicciones\n",
    "\n",
    "Ahora queremos ver los datos junto a las predicciones hachas por el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "grid = np.linspace(np.min(dfautos.horsepower), np.max(dfautos.horsepower), 100)\n",
    "\n",
    "y_fit = beta0 + beta1*grid\n",
    "\n",
    "ax.plot(grid, y_fit, '--', color='g', label='linear fit')\n",
    "ax.plot(dfautos.horsepower, dfautos.mpg, 'o', color='g', alpha=0.5, label='observed') \n",
    "ax.set_xlabel(\"HP\", fontsize=12)\n",
    "ax.set_ylabel(\"MPG\", fontsize=12)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora para el peso en `weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparar datos\n",
    "x = np.array(dfautos.weight)\n",
    "y = np.array(dfautos.mpg)\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "# realizar modelo\n",
    "regr_sm = sm.OLS(y, X)\n",
    "results_sm = regr_sm.fit()\n",
    "\n",
    "# extraer par'ametros\n",
    "beta0 = results_sm.params[0]\n",
    "beta1 = results_sm.params[1]\n",
    "\n",
    "# visualizar\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "grid = np.linspace(np.min(dfautos.weight), np.max(dfautos.weight), 100)\n",
    "y_fit_lineal = beta0 + beta1*grid\n",
    "\n",
    "ax.plot(grid, y_fit_lineal, '--', color='b', label='Linear fit')\n",
    "ax.plot(dfautos.weight, dfautos.mpg, 'o', color='b', alpha=0.5, label='Observed') \n",
    "\n",
    "ax.set_xlabel(\"Weight\", fontsize=12)\n",
    "ax.set_ylabel(\"MPG\", fontsize=12)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sm.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Regresión  Polinomial\n",
    "\n",
    "En una regresión polinomial, usamos un **modelo lineal** para estimar una **función no lineal** (i.e., una función con términos polinomiales). Por ejemplo, \n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_i + \\beta_2x_i^{2}$\n",
    "\n",
    "Es un modelo _lineal_ porque resolvemos una ecuación lineal para obtener los coeficientes $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#¿Es un buen ajuste? tal vez podemos probar con una funcion no lineal\n",
    "dfautos['wt2'] = dfautos['weight']**2\n",
    "\n",
    "# Calcular regresión lineal con \n",
    "lm1 = smf.ols('mpg ~ weight + wt2', data=dfautos).fit()\n",
    "\n",
    "# Print the estimated parameters\n",
    "print(lm1.params, lm1.rsquared)\n",
    "lm1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "xgrid = np.linspace(np.min(dfautos.weight), np.max(dfautos.weight), 100)\n",
    "\n",
    "y_fit_poly = lm1.params[0] + lm1.params[1]*xgrid + lm1.params[2]*xgrid**2\n",
    "\n",
    "ax.plot(xgrid, y_fit_poly, '--', color='r', label='Polynomial fit', lw=2)\n",
    "ax.plot(grid, y_fit_lineal, '-', color='green', label='Linear fit')\n",
    "\n",
    "ax.plot(dfautos.weight, dfautos.mpg, 'o', color='b', alpha=0.3, label='Observed') \n",
    "\n",
    "ax.set_xlabel(\"Weight\", fontsize=12)\n",
    "ax.set_ylabel(\"MPG\", fontsize=12)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_predict_lin = beta0 + beta1*x\n",
    "print('MSE lineal:', mean_squared_error(y, y_predict_lin))\n",
    "\n",
    "\n",
    "y_predict_poly = lm1.params[0] + lm1.params[1]*x + lm1.params[2]*x**2\n",
    "print('MSE poly:', mean_squared_error(y, y_predict_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regresión Multilineal\n",
    "\n",
    "### 4.1 Armando el modelo\n",
    "\n",
    "Supongamos ahora un modelo incluyendo múltiples variables:\n",
    "\n",
    "$$\\text{mpg} \\approx \\beta_0 + \\beta_1\\text{disp} + \\beta_2\\text{hp} + \\beta_3\\text{wt} +\\beta_4\\text{wt}^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def build_xmatrix(df, columns, cols_squared=[]):\n",
    "    x_matrix = df[columns].copy()\n",
    "    \n",
    "    for col in cols_squared:\n",
    "        x_matrix['%s_2'%col] = df[col]**2\n",
    "    \n",
    "    x_matrix = sm.add_constant(x_matrix)\n",
    "    return(x_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['displacement','horsepower','weight']\n",
    "cols_squared = ['weight']\n",
    "\n",
    "x_matrix = build_xmatrix(dfautos, columns, cols_squared)\n",
    "x_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "y = dfautos.mpg\n",
    "fitted_model = OLS(y, x_matrix, hasconst=True).fit()\n",
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualizando el modelo\n",
    "\n",
    "Ahora veamos cómo visualizar los resultados de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "x_wt = np.arange(dfautos['weight'].min(), dfautos['weight'].max(), 0.01)\n",
    "wtcoef = fitted_model.params.weight\n",
    "wt2coef = fitted_model.params.weight_2\n",
    "y_wt = wtcoef*x_wt + wt2coef*x_wt**2\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.plot(x_wt, y_wt)\n",
    "ax1.set_title(\"Efecto del peso del auto ('weight', 'weight'^2)\")\n",
    "ax1.set_xlabel(\"Weight\")\n",
    "ax1.set_ylabel(\"Contribución al rendimiento\")\n",
    "\n",
    "hpcoef = fitted_model.params.horsepower\n",
    "x_hp = np.arange(dfautos['horsepower'].min(), dfautos['horsepower'].max(), 0.01)\n",
    "y_hp = hpcoef*x_hp\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot(x_hp, y_hp)\n",
    "ax2.set_title(\"Efecto de HP\")\n",
    "ax2.set_xlabel(\"HP\")\n",
    "ax2.set_ylabel(\"Contribución al rendimiento\")\n",
    "\n",
    "dispcoef = fitted_model.params.displacement\n",
    "x_disp = np.arange(dfautos['displacement'].min(), dfautos['displacement'].max(), 0.01)\n",
    "y_disp = dispcoef*x_disp\n",
    "\n",
    "ax3=fig.add_subplot(133)\n",
    "ax3.plot(x_disp, y_disp)\n",
    "ax3.set_title(\"Efecto del Desplazamiento\")\n",
    "ax3.set_xlabel(\"Disp\")\n",
    "ax3.set_ylabel(\"Contribución al rendimiento\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Problemas a considerar\n",
    "\n",
    "### 5.1 Colineares\n",
    "\n",
    "Cuando tenemos datos que tienen colinearidad entre ellos, podemos tener problemas al aplicar regresiones.\n",
    "\n",
    "NOTA: para correr este gráfico en forma interactiva, deben instalar la librería `ipympl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Generate Data\n",
    "# for creating a responsive plot\n",
    "#%matplotlib widget\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "print('Generating Data')\n",
    "# sample size\n",
    "T = 200\n",
    "# number of factors\n",
    "m = 2\n",
    "# generate factor values\n",
    "x = rnd.uniform(size=(T,m))\n",
    "\n",
    "#%% Model\n",
    "# real world factors\n",
    "betaR = np.array([[2], [1]])\n",
    "\n",
    "# noise variance\n",
    "s = .4\n",
    "# observed data\n",
    "y = np.dot(x, betaR) + rnd.normal(0, s, size=(T,1))\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(x[:,0], x[:,1], y, c='r', alpha=0.1)\n",
    "ax.set_xlabel('x_1')\n",
    "ax.set_ylabel('x_2')\n",
    "ax.set_zlabel('y')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_zlim([-2, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "print('Regression Model')\n",
    "# make linear regression model\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# fit model with data\n",
    "regr.fit(x, y)\n",
    "r2 = regr.score(x, y)\n",
    "# get coefficients and fitness\n",
    "betaReg = regr.coef_[0]\n",
    "print('Coefficients: ' + str(betaReg))\n",
    "print('r2 = ' + str(r2))\n",
    "\n",
    "# build plane\n",
    "Xp, Yp = np.meshgrid(np.arange(0, 1.1, .5), np.arange(0, 1.1, .5))\n",
    "Zp = betaReg[0] * Xp + betaReg[1] * Yp\n",
    "# plot plane\n",
    "fig = plt.figure(2)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.plot_surface(Xp, Yp, Zp, linewidth=0, antialiased=False, alpha=0.9)\n",
    "ax.scatter(x[:,0], x[:,1], y, c='r', alpha=0.1)\n",
    "ax.set_xlabel('x_1')\n",
    "ax.set_ylabel('x_2')\n",
    "ax.set_zlabel('y')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_zlim([-2, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Make collinear data\n",
    "print('Generating Collinear Data')\n",
    "# generate factor values\n",
    "xCol = rnd.uniform(size=(T,m))\n",
    "xCol[:,1] = xCol[:,0] + rnd.normal(0, .0001, size=T)\n",
    "\n",
    "# observed data\n",
    "yCol = np.dot(xCol, betaR) + rnd.normal(0, s, size=(T,1))\n",
    "\n",
    "fig = plt.figure(3)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(xCol[:,0], xCol[:,1], yCol, c='r', alpha=0.1)\n",
    "ax.set_xlabel('x_1')\n",
    "ax.set_ylabel('x_2')\n",
    "ax.set_zlabel('y')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_zlim([-2, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Collinear Regression\n",
    "# make linear regression model\n",
    "regrCol = linear_model.LinearRegression()\n",
    "# fit model with data\n",
    "regrCol.fit(xCol, yCol)\n",
    "r2Col = regrCol.score(xCol, yCol)\n",
    "# get coefficients\n",
    "betaCol = regrCol.coef_[0]\n",
    "print('Coefficients: ' + str(betaCol))\n",
    "print('r2 = ' + str(r2Col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La Paradoja de Simpson\n",
    "\n",
    "Otro elemento clásico a considerar al realizar regresiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "df = pd.read_csv(\"data//berkeley.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_group = df.groupby(['Gender', 'Admission']).size().unstack()\n",
    "gender_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_group.apply(lambda x:100*x/x.sum(), axis=1).plot(kind='barh', stacked=True, legend=False)\n",
    "plt.legend(['Accepted', 'Rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Fue el sistema de admisión de Berkeley sesgado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_group_major = df.groupby(['Major', 'Gender', 'Admission']).size().unstack()\n",
    "gender_group_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_group_major.apply(lambda x:100*x/x.sum(), axis=1).plot(kind='barh', stacked=True, legend=False)\n",
    "plt.legend(['Accepted', 'Rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos por qué pasa esto con otro ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data//clientes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(df['Time_spent'], df['Satisfaction'], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "regresion = sm.OLS(df[\"Satisfaction\"], sm.add_constant(df[\"Time_spent\"])).fit()\n",
    "print(regresion.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(df['Time_spent'], df['Satisfaction'], '.')\n",
    "plt.xlabel('Time_spent')\n",
    "plt.ylabel('Satisfaction')\n",
    "x = np.array([0.2, 1.6])\n",
    "plt.plot(x, regresion.params.const + regresion.params.Time_spent*x, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(df['Time_spent'][df['Country']==0], df['Satisfaction'][df['Country']==0], 'r.')\n",
    "plt.plot(df['Time_spent'][df['Country']==1], df['Satisfaction'][df['Country']==1], 'g.')\n",
    "plt.plot(df['Time_spent'][df['Country']==2], df['Satisfaction'][df['Country']==2], 'b.')\n",
    "plt.xlabel('Time_spent')\n",
    "plt.ylabel('Satisfaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg0 = sm.OLS(df[\"Satisfaction\"][df['Country']==0], sm.add_constant(df[\"Time_spent\"][df['Country']==0])).fit()\n",
    "reg1 = sm.OLS(df[\"Satisfaction\"][df['Country']==1], sm.add_constant(df[\"Time_spent\"][df['Country']==1])).fit()\n",
    "reg2 = sm.OLS(df[\"Satisfaction\"][df['Country']==2], sm.add_constant(df[\"Time_spent\"][df['Country']==2])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(df['Time_spent'][df['Country']==0], df['Satisfaction'][df['Country']==0], 'r.')\n",
    "plt.plot(df['Time_spent'][df['Country']==1], df['Satisfaction'][df['Country']==1], 'g.')\n",
    "plt.plot(df['Time_spent'][df['Country']==2], df['Satisfaction'][df['Country']==2], 'b.')\n",
    "\n",
    "x = np.array([0.2, 1.6])\n",
    "plt.plot(x, reg0.params.const + reg0.params.Time_spent*x, '-r')\n",
    "plt.plot(x, reg1.params.const + reg1.params.Time_spent*x, '-g')\n",
    "plt.plot(x, reg2.params.const + reg2.params.Time_spent*x, '-b')\n",
    "plt.xlabel('Time_spent')\n",
    "plt.ylabel('Satisfaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "multi_model = smf.mixedlm(\"Satisfaction ~ Time_spent\", data=df, groups=df[\"Country\"], re_formula=\"Time_spent\").fit()\n",
    "print(multi_model.fe_params)\n",
    "print(multi_model.random_effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
